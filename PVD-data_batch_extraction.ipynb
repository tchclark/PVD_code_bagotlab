{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PVD Task MedPC to Excel Code - T. Chase Clark 2019 Â©\n",
    "## Use this code to clean and organize PVD (and other Pavlovian data) into a single excel line per session\n",
    "\n",
    "The below code will extract all relevant animal/trial information and head entry number, time, and duration into a single line. This will be itterated across all .csv files  and compiled into a single excel file. These data are best viewed as a pivot table to interact with the different variables.\n",
    "\n",
    "You will need to alter variables to adapt to single valence training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(trial):\n",
    "    headers = pd.read_csv(trial)\n",
    "    animal = headers.at[0,\"Subject #\"]\n",
    "    date = headers.at[0,\"StartDate\"]\n",
    "    training_day = headers.at[0, \"Experiment/Day\"]\n",
    "    trials = pd.read_csv(trial, header=3)\n",
    "    trials = trials.replace(999.00, np.nan)\n",
    "    return(trials, animal, date, training_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Chase Clark\\\\OneDrive - McGill University\\\\Bagot Lab Documents\\\\Data\\\\CSDS_PD_3_males_190621'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Direct path to folder with data\n",
    "os.chdir('C:\\\\Users\\\\Chase Clark\\\\OneDrive - McGill University\\\\Bagot Lab Documents\\\\Data\\\\CSDS_PD_3_males_190621\\\\')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSDS_PD_3_males_HE_data\\C10_190704.CSV\n",
      "CSDS_PD_3_males_HE_data\\C1_190704.CSV\n",
      "CSDS_PD_3_males_HE_data\\C2_190704.CSV\n",
      "CSDS_PD_3_males_HE_data\\C3_190704.CSV\n",
      "CSDS_PD_3_males_HE_data\\C4_190704.CSV\n",
      "CSDS_PD_3_males_HE_data\\C5_190704.CSV\n",
      "CSDS_PD_3_males_HE_data\\C6_190704.CSV\n",
      "CSDS_PD_3_males_HE_data\\C7_190704.CSV\n",
      "CSDS_PD_3_males_HE_data\\C8_190704.CSV\n",
      "CSDS_PD_3_males_HE_data\\C9_190704.CSV\n",
      "CSDS_PD_3_males_HE_data\\D10_190704.CSV\n",
      "CSDS_PD_3_males_HE_data\\D1_190704.CSV\n",
      "CSDS_PD_3_males_HE_data\\D2_190704.CSV\n",
      "CSDS_PD_3_males_HE_data\\D3_190704.CSV\n",
      "CSDS_PD_3_males_HE_data\\D4_190704.CSV\n",
      "CSDS_PD_3_males_HE_data\\D5_190704.CSV\n",
      "CSDS_PD_3_males_HE_data\\D6_190704.CSV\n",
      "CSDS_PD_3_males_HE_data\\D7_190704.CSV\n",
      "CSDS_PD_3_males_HE_data\\D8_190704.CSV\n",
      "CSDS_PD_3_males_HE_data\\D9_190704.CSV\n",
      "CSDS_PD_3_males_HE_data\\C10_190705.CSV\n",
      "CSDS_PD_3_males_HE_data\\C1_190705.CSV\n",
      "CSDS_PD_3_males_HE_data\\C2_190705.CSV\n",
      "CSDS_PD_3_males_HE_data\\C3_190705.CSV\n",
      "CSDS_PD_3_males_HE_data\\C4_190705.CSV\n",
      "CSDS_PD_3_males_HE_data\\C5_190705.CSV\n",
      "CSDS_PD_3_males_HE_data\\C6_190705.CSV\n",
      "CSDS_PD_3_males_HE_data\\C7_190705.CSV\n",
      "CSDS_PD_3_males_HE_data\\C8_190705.CSV\n",
      "CSDS_PD_3_males_HE_data\\C9_190705.CSV\n",
      "CSDS_PD_3_males_HE_data\\D10_190705.CSV\n",
      "CSDS_PD_3_males_HE_data\\D1_190705.CSV\n",
      "CSDS_PD_3_males_HE_data\\D2_190705.CSV\n",
      "CSDS_PD_3_males_HE_data\\D3_190705.CSV\n",
      "CSDS_PD_3_males_HE_data\\D4_190705.CSV\n",
      "CSDS_PD_3_males_HE_data\\D5_190705.CSV\n",
      "CSDS_PD_3_males_HE_data\\D6_190705.CSV\n",
      "CSDS_PD_3_males_HE_data\\D7_190705.CSV\n",
      "CSDS_PD_3_males_HE_data\\D8_190705.CSV\n",
      "CSDS_PD_3_males_HE_data\\D9_190705.CSV\n",
      "40 files translated!\n"
     ]
    }
   ],
   "source": [
    "#Combined App+Avr\n",
    "#Three Tone Conditioning\n",
    "#Will need to alter header names for appetitive or aversive alone experiments\n",
    "\n",
    "headers = ['Animal ID', 'Date', 'Training Day', 'CSR+ Latency', 'CS- Latency', 'CSS+ Latency',\n",
    "           'ITIR+ Latency', 'ITI- Latency', 'ITIS+ Latency',\n",
    "           'PreCSR+ HE Rate', 'Pre Reward HE Rate', 'PreCS- HE Rate', 'Pre No Outcome HE Rate',\n",
    "           'PreCSS+ HE Rate', 'Pre Shock HE Rate',\n",
    "           'CSR+ Total HE Rate', 'CS- Total HE Rate', 'CSS+ Total HE Rate',\n",
    "           'ITIR+ Total HE Rate', 'ITI- Total HE Rate', 'ITIS+ Total HE Rate',\n",
    "           'PreCSR+ HE %', 'Pre Reward HE %', 'PreCS- HE %', 'Pre No Outcome HE %',\n",
    "           'PreCSS+ HE %', 'Pre Shock HE %']\n",
    "\n",
    "sheet = pd.DataFrame()\n",
    "#enter the dates you want data for here\n",
    "#dates = ['190624', '190625', '190626', '190627','190628','190629','190630','190701','190702']\n",
    "dates = ['190704','190705']\n",
    "a = 0\n",
    "\n",
    "for d in dates:\n",
    "    string = 'CSDS_PD_3_males_HE_data\\\\*_' + d + '.CSV'\n",
    "    filenames = sorted(glob.glob(string))\n",
    "    for f in filenames:\n",
    "        print(f)\n",
    "        a += 1\n",
    "        \n",
    "        #Import Trial Data and HEs\n",
    "        trials, animal, date, training_day = import_data(f)\n",
    "        CSRpl = trials[trials[\"Trial Type\"] == 1.0]\n",
    "        CSng = trials[trials[\"Trial Type\"] == 2.0]\n",
    "        CSSpl = trials[trials[\"Trial Type\"] == 3.0]\n",
    "        \n",
    "        #Mean latency to enter during each CS and ITI type\n",
    "        CSRpl_L = CSRpl['CS HE Lat'].replace(np.nan, 15).mean()\n",
    "        CSng_L = CSng['CS HE Lat'].replace(np.nan, 15).mean()\n",
    "        ITIRpl_L = CSRpl['ITI HE Lat'].replace(np.nan, CSRpl['ITI Length']).mean()\n",
    "        ITIng_L = CSng['ITI HE Lat'].replace(np.nan, CSng['ITI Length']).mean()\n",
    "        CSSpl_L = CSSpl['CS HE Lat'].replace(np.nan, 15).mean()\n",
    "        ITISpl_L = CSSpl['ITI HE Lat'].replace(np.nan, CSSpl['ITI Length']).mean()\n",
    "\n",
    "        #Mean HE Rate during and before and during each CS type\n",
    "        preCSRpl_R = CSRpl['Pre CS HE'].mean()/10\n",
    "        preUSRpl_R = CSRpl['Pre US HE'].mean()/10\n",
    "        preCSng_R = CSng['Pre CS HE'].mean()/10\n",
    "        preUSng_R = CSng['Pre US HE'].mean()/10\n",
    "        preCSSpl_R = CSSpl['Pre CS HE'].mean()/10\n",
    "        preUSSpl_R = CSSpl['Pre US HE'].mean()/10\n",
    "\n",
    "        #Mean HE Rate during each CS and ITI\n",
    "        CSRpl_R = CSRpl['CS HE'].mean()/15\n",
    "        CSng_R = CSng['CS HE'].mean()/15\n",
    "        ITIRpl_R = (CSRpl['ITI HE']/CSRpl['ITI Length']).mean()\n",
    "        ITIng_R = (CSng['ITI HE']/CSng['ITI Length']).mean()\n",
    "        CSSpl_R = CSSpl['CS HE'].mean()/15\n",
    "        ITISpl_R = (CSSpl['ITI HE']/CSSpl['ITI Length']).mean()\n",
    "        \n",
    "        #Mean % time in foodport during and before and during each CS type\n",
    "        \n",
    "        preCSRpl_per = CSRpl['Pre CS time'].mean()/10\n",
    "        preUSRpl_per = CSRpl['Pre US time'].mean()/10\n",
    "        preCSng_per = CSng['Pre CS time'].mean()/10\n",
    "        preUSng_per = CSng['Pre US time'].mean()/10\n",
    "        preCSSpl_per = CSSpl['Pre CS time'].mean()/10\n",
    "        preUSSpl_per = CSSpl['Pre US time'].mean()/10\n",
    "        \n",
    "        session = np.array([animal, date, training_day,CSRpl_L, CSng_L, CSSpl_L,\n",
    "                            ITIRpl_L, ITIng_L, ITISpl_L,\n",
    "                            preCSRpl_R, preUSRpl_R, preCSng_R, preUSng_R,\n",
    "                            preCSSpl_R, preUSSpl_R,\n",
    "                            CSRpl_R, CSng_R, CSSpl_R,\n",
    "                            ITIRpl_R, ITIng_R, ITISpl_R,\n",
    "                            preCSRpl_per, preUSRpl_per, preCSng_per,\n",
    "                            preUSng_per, preCSSpl_per, preUSSpl_per])\n",
    "        session = pd.DataFrame(session)\n",
    "        sheet = sheet.append(session.T, ignore_index=True)\n",
    "sheet.columns = headers\n",
    "num = str(a) + \" files translated!\"\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('CSDS_PD_3_males_exported/190704-05_data2.xlsx')\n",
    "sheet.to_excel(writer,'Data')\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
